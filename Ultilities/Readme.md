# SQuAD Filter

The `filter.py` file contains the source code used to take x% best data in a SQuAD-format dataset based on a score file

**To run the code**

```sh
python filter.py -train <train_file> -score <score_file>
```
Where: 
- `-train` or `--train_file` The path to the Zalo-format dataset that need to be filtered
- `-score` or `--score_file` A CSV file that score each data instance in the above dataset
- `-top` or `--get_top_percentage` The percentage of best result to get (0 to 1)
- `-out` or `--output_file` The desired path where the filtered data should be stored
- `-e` or `--encoding` The encoding of the input & the desired output dataset

The train file contains the translated SQuAD dataset, while the score file indicate translation quality for each qa-pair,
generated by running the model in evaluate mode for the dataset that need to be filtered


# SQuAD Translate

The `squad_translate_1.py` file contains the source code to translate SQuAD dataset from English to Vietnamese

**Additional Requirements**

	* copy
	* html
	* google.cloud (Authentication is required, which is not included in this CD)

**To run the code**

```sh
export GOOGLE_APPLICATION_CREDENTIALS="<path_to_authenticate_file>"
python squad_translate_1.py -in <input_file> -out <output_file>
```

Where: 
- `-in` or `--input_file` The path to the input SQuAD v1.1 datset that need to be translated
- `-out` or `--output_file` The desired path where the translated datset should be saved
- `-e` or `--encoding` The encoding of the input & the desired output dataset

Along with the output translated file, `error.txt` and `progress.json` are returned indicates question-answer pairs with errors that can be processes; and current progress so that the program can be continued after termination.

The `squad_translate_2.py` file contains the source code to translate the **ADDITIONAL** data from SQuAD v2.0 (contains unansweable question) from English to Vietnamese

**Additional Requirements**

	* selenium

**To run the code**

```sh
python squad_translate_2.py -i <input_file> -o <output_file> -e <encoding> -t <num_threads>
```

Where: 
- `-i` or `--input_file` The path to the input additional SQuAD v2.0 datset that need to be translated
- `-o` or `--output_file` The desired path where the translated datset should be saved
- `-e` or `--encoding` The encoding of the input & the desired output dataset
- `t` or `--num_threads` The number of threads the script should run


# SQuAD to Zalo format dataset converter

This `convert_squad2zalo_format.py` file contains the source code to convert a dataset (json) file from SQuAD v2.0 format to Zalo-defined format

**Run the code**
```sh
python convert_squad2zalo_format.py -i <input_file> -o <output_file> -m <mode>
```

Where
- `-i` or `--input_file` The path to the input SQuAD datset that need to be converted
- `-o` or `--output_file` The desired path where the output Zalo-formatted datset should be saved
- `-e` or `--encoding` The encoding of the input & the desired output dataset
- `-m` or `--mode` Which conversion mechanism should be used (*'full'* or *'short'*), which determine the `text` label for each question in the Zalo-formatted dataset

    - `full`: `text` will be the full `paragraph` in the source SQuAD dataset
    - `short`: `text` will get all the possible sentences, where the length of `question` & `text` does not surpass a certain threshold (the sentence that contains the `answer` in the `paragraph` must be present if an answer is present)
    - `veryshort`: `text` will be the sentence that contains the answer, or a random sentence if no answer is found

- `-s` or `--size` The maximum combined length of 'question' & 'text' allowed (used in mode 'short)    

# Prepare pretrain data

The `extract_wiki_to_pretrain_format.py` file contains the source code to convert a Wikipedia-extracted dump to BERT pretrained data (unprocessed)

**Run the code**
```sh
python extract_wiki_to_pretrain_format.py -i <input_file> -o <output_file>
```

Where
- `-i` or `--input_file` The path to the extracted Wikipedia file, each line is a article in json string
- `-o` or `--output` The desired path to the (unprocessed) output pretrain data

To get the extracted Vietnamese Wikipedia dump, download the [latest dump](https://dumps.wikimedia.org/viwiki/latest/viwiki-latest-pages-articles.xml.bz2), then extract the text with [WikiExtractor.py](https://github.com/attardi/wikiextractor), remember to choose the `--json` flag to match the required input format.

# Backtranslation

This `dab.py` file contains the source code to generate paraphrases from a Zalo-defined dataset (json) using backtranslation

**Run the code**
```sh
python dab.py -i <input_file> -o <output_file>/
```

Where
- `-i` or `--input_file` The path to the input Zalo-defined datset that need to be paraphrased
- `-o` or `--output_file` The desired path where the output Zalo-formatted datset should be saved
- `-l` or `--inter_lang` The "middle" language used for backtranslation
- `-t` or `--num_threads` The number of threads used
- `-e` or `--encoding` The encoding of the input & the desired output dataset
